{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The building blocks of DL 2\n",
    "\n",
    "> Simplest Neural Network: linear layer with activation function\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [medicalnist, mnist, basic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous post](https://ml4med.github.io/blog/basic/sgd/2020/07/20/building-blocks-of-dl-sgd.html) I've explained what is the most important concept in neural networks - technique that allows us to incrementally find minimum of a function. This is called Gradient Descent algorithm!\n",
    "\n",
    "In this post I will build on this concept and show you how to create a basic linear model to predict what is on a medical image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "As in the [first post](https://ml4med.github.io/blog/medicalnist/mnist/basic/2020/06/19/fist_post.html) showing how to build medical image recognition with pure statistics, we need to download data first. For some basic description of how the data looks like, see that [first post](https://ml4med.github.io/blog/medicalnist/mnist/basic/2020/06/19/fist_post.html) first ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Medical-MNIST-Classification'...\n",
      "remote: Enumerating objects: 58532, done.\u001b[K\n",
      "remote: Total 58532 (delta 0), reused 0 (delta 0), pack-reused 58532\u001b[K\n",
      "Receiving objects: 100% (58532/58532), 77.86 MiB | 20.76 MiB/s, done.\n",
      "Resolving deltas: 100% (506/506), done.\n",
      "Checking connectivity... done.\n",
      "Checking out files: 100% (58959/58959), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/apolanco3225/Medical-MNIST-Classification.git\n",
    "! mv Medical-MNIST-Classification/resized/ ./medical_mnist\n",
    "! rm -rf Medical-MNIST-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"medical_mnist/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have much more powerful tools now, so we will deal with all 6 classes now, but first need to prepare data:\n",
    " - all data needs to be numerical\n",
    " - it needs to be in arrays\n",
    " - it needs to be labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = !ls {PATH}\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for cls in classes:\n",
    "    images[cls] = !ls {PATH/cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToTensor converts images to tensorts\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "image_tensors = {}\n",
    "\n",
    "for cls in classes:\n",
    "    image_tensors[cls] = torch.stack(\n",
    "        [\n",
    "            ToTensor()(\n",
    "                Image.open(path)\n",
    "            ).view(-1, 64 * 64).squeeze().float()/255 \n",
    "            \n",
    "            for path in (PATH/cls).iterdir()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT has 10000 images of a size torch.Size([4096])\n",
      "BreastMRI has 8954 images of a size torch.Size([4096])\n",
      "CXR has 10000 images of a size torch.Size([4096])\n",
      "ChestCT has 10000 images of a size torch.Size([4096])\n",
      "Hand has 10000 images of a size torch.Size([4096])\n",
      "HeadCT has 10000 images of a size torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "for cls in classes:\n",
    "    class_shape = image_tensors[cls].shape\n",
    "    print(f\"{cls} has {class_shape[0]} images of a size {class_shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.cat([image_tensors[cls] for cls in classes], dim=0)\n",
    "y_train = torch.cat([torch.tensor([index] * image_tensors[cls].shape[0]) for index, cls in enumerate(classes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle the dataset. This is important as if we don't do this, images from the classes that we train first will be effectively not as \"fresh\" in the memmory of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = torch.randperm(x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[permutations]\n",
    "y_train = y_train[permutations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create validation set that is 20% of the training set - this is important to asses the performance of the model. Validation set doesn't take part in training, so model is not biased towards those images (it cannot remember those exact images from training). This is essential to see how well model generalizes on examples it has not seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11790"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pct = 0.2\n",
    "valid_index = int(x_train.shape[0] * valid_pct)\n",
    "valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take out first 20% of examples from the training set\n",
    "x_valid = x_train[:valid_index]\n",
    "y_valid = y_train[:valid_index]\n",
    "\n",
    "x_train = x_train[valid_index:]\n",
    "y_train = y_train[valid_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([47164, 4096]),\n",
       " torch.Size([47164]),\n",
       " torch.Size([11790, 4096]),\n",
       " torch.Size([11790]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
