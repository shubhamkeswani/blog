{
  
    
        "post0": {
            "title": "The building blocks of DL 1",
            "content": "Deep learning is so simple that it is hard to believe. Especially with how much magical it seems at first. At it&#39;s core is a piece of code that allows, one step at a time, to be just a bit closer to the solution. You can think of it like the way of finding the top of the mountain: . . Vocabulary: . step - single step of the optimization algorithm that makes parameters of a function just a bit better | gradient - the slope of the loss function, that we want to minimize | learning rate - how fast we adjust parameters based on the gradient | . Task: Find minimum for $f: a x^2 + b$ with Gradient Descent . We have single variable here: $x$. With Gradient Descent we&#39;ll find the value where $f$ is minimal. . In short, gradient descent is an algorithm that walks down the slope - no more no less. . An example function $f$ in python looks like this: . def f(x): return 1.2 * x**2 + 4 . To compute gradient at where we are now, we will use PyTorch magic: . import torch x = torch.tensor(-3.).requires_grad_() . To walk along the function, we will change $x$ by the fraction of the gradient (gradient * learning_rate) . learning_rate = 0.2 . and this is gradient descent algorightm in code: . # single step of the gradient descent algorithm def step(x, f): # compute y at a given value of x y = f(x) # the backward function of PyTorch tensor computes gradients y.backward() # change value of x in a direction where function decreases # (don&#39;t bother about x.data and x.grad = None - it is just necessary boilerplate) x.data = x - learning_rate * x.grad.data x.grad = None return x . gather x-es and y-s for 10 iterations . xypairs = [] for i in range(10): xypairs.append([x.data, f(x)]) print(f&quot;f({x:.2}) = {f(x):.2}&quot;) x = step(x, f) . f(-3.0) = 1.5e+01 f(-1.6) = 6.9 f(-0.81) = 4.8 f(-0.42) = 4.2 f(-0.22) = 4.1 f(-0.11) = 4.0 f(-0.059) = 4.0 f(-0.031) = 4.0 f(-0.016) = 4.0 f(-0.0083) = 4.0 . &lt;/input&gt; Once Loop Reflect And believe it or not, this is the building block of each the Neural Net - gradient descent algirithm. Stay tuned for the next post where we will use it on a MedicalNist dataset. .",
            "url": "https://ml4med.github.io/blog/basic/sgd/2020/07/20/building-blocks-of-dl-sgd.html",
            "relUrl": "/basic/sgd/2020/07/20/building-blocks-of-dl-sgd.html",
            "date": " • Jul 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "MedicalNIST the most basic prediction technique",
            "content": "To start off the blog, I&#39;ve chosen the most basic example I could come up with: . Medical imaging categorization based on comparison between the &quot;statistically average&quot; image from a category and a set of test images. . This will be used to build upon using more advanced techniques, so stay tuned! . But first let&#39;s download the data . ! rm -rf ./medical_mnist ! git clone https://github.com/apolanco3225/Medical-MNIST-Classification.git ! mv Medical-MNIST-Classification/resized/ ./medical_mnist ! rm -rf Medical-MNIST-Classification . Cloning into &#39;Medical-MNIST-Classification&#39;... remote: Enumerating objects: 58532, done. remote: Total 58532 (delta 0), reused 0 (delta 0), pack-reused 58532 Receiving objects: 100% (58532/58532), 77.86 MiB | 4.39 MiB/s, done. Resolving deltas: 100% (506/506), done. Checking connectivity... done. Checking out files: 100% (58959/58959), done. . install useful libraries . ## run this if you don&#39;t have pytorch and fastai2 installed # !pip install torch torchvision . data will be downloaded to medical_mnist folder . from pathlib import Path data = Path(&#39;medical_mnist&#39;) list(data.iterdir()) . [PosixPath(&#39;medical_mnist/AbdomenCT&#39;), PosixPath(&#39;medical_mnist/BreastMRI&#39;), PosixPath(&#39;medical_mnist/CXR&#39;), PosixPath(&#39;medical_mnist/ChestCT&#39;), PosixPath(&#39;medical_mnist/Hand&#39;), PosixPath(&#39;medical_mnist/HeadCT&#39;)] . let&#39;s see what we have here... as this is the most basic technique, let&#39;s pick the images that look the most different from each other . import matplotlib.pyplot as plt from PIL import Image for d in data.iterdir(): print(d) plt.imshow(Image.open(list(d.iterdir())[0])) plt.show() . medical_mnist/AbdomenCT . medical_mnist/BreastMRI . medical_mnist/CXR . medical_mnist/ChestCT . medical_mnist/Hand . medical_mnist/HeadCT . load the data into tensors . import torch from torchvision.transforms import ToTensor stacked_cxrs = torch.stack([ToTensor()(Image.open(path)).float()/255 for path in (data/&#39;CXR&#39;).iterdir()]) stacked_heads = torch.stack([ToTensor()(Image.open(path)).float()/255 for path in (data/&#39;HeadCT&#39;).iterdir()]) . as a good practice, let&#39;s look at the first image, so see if we did it correctly . plt.imshow(stacked_cxrs[0][0]) . &lt;matplotlib.image.AxesImage at 0x7f2198995610&gt; . now, let&#39;s build &quot;ideal&quot; image for each of the category. This ideal image is just a mean for each pixel across all the images . mean_cxrs = stacked_cxrs.mean(0) plt.imshow(mean_cxrs[0]) . &lt;matplotlib.image.AxesImage at 0x7f21717d1590&gt; . mean_headct = stacked_heads.mean(0) plt.imshow(mean_headct[0]) . &lt;matplotlib.image.AxesImage at 0x7f211f6b6a50&gt; . now we can see how much example image differs from the ideals: . import torch.nn.functional as F . F.mse_loss(stacked_cxrs[0], mean_cxrs).sqrt() . tensor(0.0010) . F.mse_loss(stacked_cxrs[0], mean_headct).sqrt() . tensor(0.0016) . looks like that one was a CXR indeed - L2 loss between ideal image from CXR category (mean_cxrs) was lower . so let&#39;s build a simple classifier function, that predicts whether image is a headct or not . def is_headct(img_tensor): if F.mse_loss(img_tensor, mean_cxrs) &gt; F.mse_loss(img_tensor, mean_headct): return True else: return False . now we test the classifier . cxrs_preds = torch.tensor([not is_headct(stacked_cxrs[i]) for i in range(stacked_cxrs.shape[0])]) cxrs_accuracy = cxrs_preds.sum().float() / cxrs_preds.shape[0] print(f&#39;Accuracy on CXRs: {round( (cxrs_accuracy).item() * 100, 2)}%&#39;) . Accuracy on CXRs: 99.15% . head_preds = torch.tensor([is_headct(stacked_heads[i]) for i in range(stacked_heads.shape[0])]) head_accuracy = head_preds.sum().float() / head_preds.shape[0] print(f&#39;Accuracy on HeadCTs: {round( (head_accuracy).item() * 100, 2)}%&#39;) . Accuracy on HeadCTs: 100.0% . ... of course: . those classes were the most distinguishable from each other and | we didn&#39;t split into train and test sets here so results are biased (as each image we predict was used to figure out the &quot;ideal&quot; image) | but this was a nice start of this blog :) .",
            "url": "https://ml4med.github.io/blog/medicalnist/mnist/basic/2020/06/19/fist_post.html",
            "relUrl": "/medicalnist/mnist/basic/2020/06/19/fist_post.html",
            "date": " • Jun 19, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ml4med.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there, . My name is Michał Pawłowski and I am a data engineering consultant for a pharma company. . Here I will post my learnings and experiments with ML and AI in the field of medicine. . If you want to find our a bit more about me, see linkedin .",
          "url": "https://ml4med.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ml4med.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}